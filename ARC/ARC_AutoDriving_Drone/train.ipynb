{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0  파일 길이 :  96\n",
      "a0  :  C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train//a0\\1.jpg\n",
      "a1  파일 길이 :  37\n",
      "a1  :  C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train//a1\\136.jpg\n",
      "b0  파일 길이 :  43\n",
      "b0  :  C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train//b0\\147.jpg\n",
      "b1  파일 길이 :  37\n",
      "b1  :  C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train//b1\\163.jpg\n",
      "c0  파일 길이 :  36\n",
      "c0  :  C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train//c0\\167.jpg\n",
      "c1  파일 길이 :  16\n",
      "c1  :  C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train//c1\\178.jpg\n",
      "ok 265\n"
     ]
    }
   ],
   "source": [
    "caltech_dir = \"C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/img_others/train/\"\n",
    "categories = [\"a0\",\"a1\",\"b0\",\"b1\",\"c0\",\"c1\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 60\n",
    "image_h = 60\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"LA\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/numpy_data/multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dahyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dahyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dahyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dahyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dahyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dahyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 60, 60, 2)\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/numpy_data/multi_image_data.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"a0\",\"a1\",\"b0\",\"b1\",\"c0\",\"c1\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = 'C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 60, 60, 16)        304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 30, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1024)              6423552   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 7,098,230\n",
      "Trainable params: 7,098,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 198 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "198/198 [==============================] - 10s 51ms/step - loss: 1.9404 - acc: 0.2778 - val_loss: 1.7625 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.76252, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.6995 - acc: 0.3636 - val_loss: 1.7713 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.76252\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.6681 - acc: 0.3737 - val_loss: 1.7370 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.76252 to 1.73702, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 1.6132 - acc: 0.3838 - val_loss: 1.7530 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.73702\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 1.6311 - acc: 0.3788 - val_loss: 1.7274 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.73702 to 1.72741, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 1.6838 - acc: 0.3788 - val_loss: 1.7552 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.72741\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.6559 - acc: 0.3737 - val_loss: 1.7518 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.72741\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 1.5975 - acc: 0.3788 - val_loss: 1.7142 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.72741 to 1.71424, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 1.5966 - acc: 0.3687 - val_loss: 1.7021 - val_acc: 0.3134\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.71424 to 1.70207, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.4724 - acc: 0.4293 - val_loss: 1.5664 - val_acc: 0.4030\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.70207 to 1.56644, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.2409 - acc: 0.5202 - val_loss: 1.3795 - val_acc: 0.4627\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.56644 to 1.37949, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 1.1517 - acc: 0.5657 - val_loss: 1.3282 - val_acc: 0.4179\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.37949 to 1.32822, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.0305 - acc: 0.5606 - val_loss: 1.1743 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.32822 to 1.17431, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.8441 - acc: 0.7222 - val_loss: 1.0999 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.17431 to 1.09994, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.8924 - acc: 0.6212 - val_loss: 0.9909 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.09994 to 0.99095, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.7507 - acc: 0.7071 - val_loss: 1.0011 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.99095\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.7128 - acc: 0.7525 - val_loss: 0.9764 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.99095 to 0.97640, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.7713 - acc: 0.7273 - val_loss: 0.7281 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.97640 to 0.72812, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.6064 - acc: 0.7626 - val_loss: 0.7064 - val_acc: 0.8209\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.72812 to 0.70642, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.4826 - acc: 0.8535 - val_loss: 0.6754 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.70642 to 0.67545, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.4481 - acc: 0.8586 - val_loss: 0.5379 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.67545 to 0.53786, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.3060 - acc: 0.8939 - val_loss: 0.5233 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.53786 to 0.52326, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.2930 - acc: 0.9242 - val_loss: 0.3790 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.52326 to 0.37898, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.2005 - acc: 0.9444 - val_loss: 0.3740 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.37898 to 0.37397, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 3s 16ms/step - loss: 0.1892 - acc: 0.9293 - val_loss: 0.3500 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.37397 to 0.34996, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.1237 - acc: 0.9596 - val_loss: 0.3925 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34996\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.1682 - acc: 0.9444 - val_loss: 0.3133 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34996 to 0.31330, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.1327 - acc: 0.9596 - val_loss: 0.3260 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.31330\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0990 - acc: 0.9798 - val_loss: 0.3802 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.31330\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.1183 - acc: 0.9596 - val_loss: 0.3794 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.31330\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.1089 - acc: 0.9596 - val_loss: 0.3052 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.31330 to 0.30525, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.1004 - acc: 0.9747 - val_loss: 0.4339 - val_acc: 0.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_loss did not improve from 0.30525\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.0737 - acc: 0.9747 - val_loss: 0.4045 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.30525\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.0929 - acc: 0.9747 - val_loss: 0.2977 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.30525 to 0.29770, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.0630 - acc: 0.9747 - val_loss: 0.2995 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.29770\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.0411 - acc: 0.9899 - val_loss: 0.4285 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.29770\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.0658 - acc: 0.9747 - val_loss: 0.3646 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.29770\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.0677 - acc: 0.9798 - val_loss: 0.2771 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.29770 to 0.27711, saving model to C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 3s 16ms/step - loss: 0.0576 - acc: 0.9798 - val_loss: 0.2828 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.27711\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0477 - acc: 0.9798 - val_loss: 0.3897 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.27711\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.2156 - acc: 0.9545 - val_loss: 0.4466 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.27711\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.1460 - acc: 0.9545 - val_loss: 0.4245 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.27711\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0804 - acc: 0.9747 - val_loss: 0.3383 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.27711\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.0487 - acc: 0.9949 - val_loss: 0.3237 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.27711\n"
     ]
    }
   ],
   "source": [
    "#데이터셋이 적어서 validation을 그냥 test 데이터로 했습니다. \n",
    "#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다. \n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test) , callbacks=[checkpoint,\n",
    "                                                                                                              early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 4ms/step\n",
      "정확도 : 0.9254\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "caltech_dir = \"C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/multi_img_data/imgs_others_test\"\n",
    "image_w = 60\n",
    "image_h = 60\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"LA\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "model = load_model('C:/Users/dahyun/Desktop/ARC_AutoDriving_Drone/model/multi_img_classification.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    #print(i)\n",
    "    #print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"a0\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"a1\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"b0\"\n",
    "    elif pre_ans == 3: pre_ans_str = \"b1\"\n",
    "    elif pre_ans == 4: pre_ans_str = \"c0\"\n",
    "    elif pre_ans == 5: pre_ans_str = \"c1\"\n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[4] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[5] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
